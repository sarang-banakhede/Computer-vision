{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34cf6395",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-07T01:57:25.941660Z",
     "iopub.status.busy": "2024-07-07T01:57:25.941115Z",
     "iopub.status.idle": "2024-07-07T01:57:33.510327Z",
     "shell.execute_reply": "2024-07-07T01:57:33.509572Z"
    },
    "papermill": {
     "duration": 7.579411,
     "end_time": "2024-07-07T01:57:33.512632",
     "exception": false,
     "start_time": "2024-07-07T01:57:25.933221",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, einsum\n",
    "import numpy as np\n",
    "from einops import rearrange, repeat\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from torch.utils.data import WeightedRandomSampler\n",
    "import os\n",
    "import h5py\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch.nn.functional as f\n",
    "from io import BytesIO\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a553d093",
   "metadata": {
    "papermill": {
     "duration": 0.006473,
     "end_time": "2024-07-07T01:57:33.525974",
     "exception": false,
     "start_time": "2024-07-07T01:57:33.519501",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed300a86",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-07T01:57:33.540872Z",
     "iopub.status.busy": "2024-07-07T01:57:33.540028Z",
     "iopub.status.idle": "2024-07-07T01:57:33.549686Z",
     "shell.execute_reply": "2024-07-07T01:57:33.548955Z"
    },
    "papermill": {
     "duration": 0.018982,
     "end_time": "2024-07-07T01:57:33.551460",
     "exception": false,
     "start_time": "2024-07-07T01:57:33.532478",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CyclicShift(nn.Module):\n",
    "    def __init__(self, displacement):\n",
    "        super().__init__()\n",
    "        self.displacement = displacement\n",
    "\n",
    "    def forward(self, x):\n",
    "        return torch.roll(x, shifts=(self.displacement, self.displacement), dims=(1, 2))\n",
    "\n",
    "\n",
    "class Residual(nn.Module):\n",
    "    def __init__(self, fn):\n",
    "        super().__init__()\n",
    "        self.fn = fn\n",
    "\n",
    "    def forward(self, x, **kwargs):\n",
    "        return self.fn(x, **kwargs) + x\n",
    "\n",
    "\n",
    "class PreNorm(nn.Module):\n",
    "    def __init__(self, dim, fn):\n",
    "        super().__init__()\n",
    "        self.norm = nn.LayerNorm(dim)\n",
    "        self.fn = fn\n",
    "\n",
    "    def forward(self, x, **kwargs):\n",
    "        return self.fn(self.norm(x), **kwargs)\n",
    "\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, dim, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(dim, hidden_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(hidden_dim, dim),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac3ba60c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-07T01:57:33.566047Z",
     "iopub.status.busy": "2024-07-07T01:57:33.565508Z",
     "iopub.status.idle": "2024-07-07T01:57:33.572977Z",
     "shell.execute_reply": "2024-07-07T01:57:33.572176Z"
    },
    "papermill": {
     "duration": 0.016801,
     "end_time": "2024-07-07T01:57:33.574803",
     "exception": false,
     "start_time": "2024-07-07T01:57:33.558002",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_mask(window_size, displacement, upper_lower, left_right):\n",
    "    mask = torch.zeros(window_size ** 2, window_size ** 2)\n",
    "\n",
    "    if upper_lower:\n",
    "        mask[-displacement * window_size:, :-displacement * window_size] = float('-inf')\n",
    "        mask[:-displacement * window_size, -displacement * window_size:] = float('-inf')\n",
    "\n",
    "    if left_right:\n",
    "        mask = rearrange(mask, '(h1 w1) (h2 w2) -> h1 w1 h2 w2', h1=window_size, h2=window_size)\n",
    "        mask[:, -displacement:, :, :-displacement] = float('-inf')\n",
    "        mask[:, :-displacement, :, -displacement:] = float('-inf')\n",
    "        mask = rearrange(mask, 'h1 w1 h2 w2 -> (h1 w1) (h2 w2)')\n",
    "\n",
    "    return mask\n",
    "\n",
    "\n",
    "def get_relative_distances(window_size):\n",
    "    indices = torch.tensor(np.array([[x, y] for x in range(window_size) for y in range(window_size)]))\n",
    "    distances = indices[None, :, :] - indices[:, None, :]\n",
    "    return distances\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab933fdb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-07T01:57:33.589579Z",
     "iopub.status.busy": "2024-07-07T01:57:33.589087Z",
     "iopub.status.idle": "2024-07-07T01:57:33.603626Z",
     "shell.execute_reply": "2024-07-07T01:57:33.602858Z"
    },
    "papermill": {
     "duration": 0.024164,
     "end_time": "2024-07-07T01:57:33.605561",
     "exception": false,
     "start_time": "2024-07-07T01:57:33.581397",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class WindowAttention(nn.Module):\n",
    "    def __init__(self, dim, heads, head_dim, shifted, window_size, relative_pos_embedding):\n",
    "        super().__init__()\n",
    "        inner_dim = head_dim * heads\n",
    "\n",
    "        self.heads = heads\n",
    "        self.scale = head_dim ** -0.5\n",
    "        self.window_size = window_size\n",
    "        self.relative_pos_embedding = relative_pos_embedding\n",
    "        self.shifted = shifted\n",
    "\n",
    "        if self.shifted:\n",
    "            displacement = window_size // 2\n",
    "            self.cyclic_shift = CyclicShift(-displacement)\n",
    "            self.cyclic_back_shift = CyclicShift(displacement)\n",
    "            self.upper_lower_mask = nn.Parameter(create_mask(window_size=window_size, displacement=displacement,\n",
    "                                                             upper_lower=True, left_right=False), requires_grad=False)\n",
    "            self.left_right_mask = nn.Parameter(create_mask(window_size=window_size, displacement=displacement,\n",
    "                                                            upper_lower=False, left_right=True), requires_grad=False)\n",
    "\n",
    "        self.to_qkv = nn.Linear(dim, inner_dim * 3, bias=False)\n",
    "\n",
    "        if self.relative_pos_embedding:\n",
    "            self.relative_indices = get_relative_distances(window_size) + window_size - 1\n",
    "            self.pos_embedding = nn.Parameter(torch.randn(2 * window_size - 1, 2 * window_size - 1))\n",
    "        else:\n",
    "            self.pos_embedding = nn.Parameter(torch.randn(window_size ** 2, window_size ** 2))\n",
    "\n",
    "        self.to_out = nn.Linear(inner_dim, dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.shifted:\n",
    "            x = self.cyclic_shift(x)\n",
    "\n",
    "        b, n_h, n_w, _, h = *x.shape, self.heads\n",
    "\n",
    "        qkv = self.to_qkv(x).chunk(3, dim=-1)\n",
    "        nw_h = n_h // self.window_size\n",
    "        nw_w = n_w // self.window_size\n",
    "\n",
    "        q, k, v = map(\n",
    "            lambda t: rearrange(t, 'b (nw_h w_h) (nw_w w_w) (h d) -> b h (nw_h nw_w) (w_h w_w) d',\n",
    "                                h=h, w_h=self.window_size, w_w=self.window_size), qkv)\n",
    "\n",
    "        dots = einsum('b h w i d, b h w j d -> b h w i j', q, k) * self.scale\n",
    "\n",
    "        if self.relative_pos_embedding:\n",
    "            dots += self.pos_embedding[self.relative_indices[:, :, 0], self.relative_indices[:, :, 1]]\n",
    "        else:\n",
    "            dots += self.pos_embedding\n",
    "\n",
    "        if self.shifted:\n",
    "            dots[:, :, -nw_w:] += self.upper_lower_mask\n",
    "            dots[:, :, nw_w - 1::nw_w] += self.left_right_mask\n",
    "\n",
    "        attn = dots.softmax(dim=-1)\n",
    "\n",
    "        out = einsum('b h w i j, b h w j d -> b h w i d', attn, v)\n",
    "        out = rearrange(out, 'b h (nw_h nw_w) (w_h w_w) d -> b (nw_h w_h) (nw_w w_w) (h d)',\n",
    "                        h=h, w_h=self.window_size, w_w=self.window_size, nw_h=nw_h, nw_w=nw_w)\n",
    "        out = self.to_out(out)\n",
    "\n",
    "        if self.shifted:\n",
    "            out = self.cyclic_back_shift(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd514582",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-07T01:57:33.619660Z",
     "iopub.status.busy": "2024-07-07T01:57:33.619382Z",
     "iopub.status.idle": "2024-07-07T01:57:33.625328Z",
     "shell.execute_reply": "2024-07-07T01:57:33.624545Z"
    },
    "papermill": {
     "duration": 0.015006,
     "end_time": "2024-07-07T01:57:33.627197",
     "exception": false,
     "start_time": "2024-07-07T01:57:33.612191",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SwinBlock(nn.Module):\n",
    "    def __init__(self, dim, heads, head_dim, mlp_dim, shifted, window_size, relative_pos_embedding):\n",
    "        super().__init__()\n",
    "        self.attention_block = Residual(PreNorm(dim, WindowAttention(dim=dim,\n",
    "                                                                     heads=heads,\n",
    "                                                                     head_dim=head_dim,\n",
    "                                                                     shifted=shifted,\n",
    "                                                                     window_size=window_size,\n",
    "                                                                     relative_pos_embedding=relative_pos_embedding)))\n",
    "        self.mlp_block = Residual(PreNorm(dim, FeedForward(dim=dim, hidden_dim=mlp_dim)))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.attention_block(x)\n",
    "        x = self.mlp_block(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f1ca82ca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-07T01:57:33.641153Z",
     "iopub.status.busy": "2024-07-07T01:57:33.640892Z",
     "iopub.status.idle": "2024-07-07T01:57:33.647158Z",
     "shell.execute_reply": "2024-07-07T01:57:33.646428Z"
    },
    "papermill": {
     "duration": 0.01525,
     "end_time": "2024-07-07T01:57:33.648991",
     "exception": false,
     "start_time": "2024-07-07T01:57:33.633741",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class PatchMerging(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, downscaling_factor):\n",
    "        super().__init__()\n",
    "        self.downscaling_factor = downscaling_factor\n",
    "        self.patch_merge = nn.Unfold(kernel_size=downscaling_factor, stride=downscaling_factor, padding=0)\n",
    "        self.linear = nn.Linear(in_channels * downscaling_factor ** 2, out_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, c, h, w = x.shape\n",
    "        new_h, new_w = h // self.downscaling_factor, w // self.downscaling_factor\n",
    "        x = self.patch_merge(x).view(b, -1, new_h, new_w).permute(0, 2, 3, 1)\n",
    "        x = self.linear(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d9f3e79a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-07T01:57:33.663775Z",
     "iopub.status.busy": "2024-07-07T01:57:33.663497Z",
     "iopub.status.idle": "2024-07-07T01:57:33.671318Z",
     "shell.execute_reply": "2024-07-07T01:57:33.670582Z"
    },
    "papermill": {
     "duration": 0.017657,
     "end_time": "2024-07-07T01:57:33.673076",
     "exception": false,
     "start_time": "2024-07-07T01:57:33.655419",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class StageModule(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_dimension, layers, downscaling_factor, num_heads, head_dim, window_size,\n",
    "                 relative_pos_embedding):\n",
    "        super().__init__()\n",
    "        assert layers % 2 == 0, 'Stage layers need to be divisible by 2 for regular and shifted block.'\n",
    "\n",
    "        self.patch_partition = PatchMerging(in_channels=in_channels, out_channels=hidden_dimension,\n",
    "                                            downscaling_factor=downscaling_factor)\n",
    "\n",
    "        self.layers = nn.ModuleList([])\n",
    "        for _ in range(layers // 2):\n",
    "            self.layers.append(nn.ModuleList([\n",
    "                SwinBlock(dim=hidden_dimension, heads=num_heads, head_dim=head_dim, mlp_dim=hidden_dimension * 4,\n",
    "                          shifted=False, window_size=window_size, relative_pos_embedding=relative_pos_embedding),\n",
    "                SwinBlock(dim=hidden_dimension, heads=num_heads, head_dim=head_dim, mlp_dim=hidden_dimension * 4,\n",
    "                          shifted=True, window_size=window_size, relative_pos_embedding=relative_pos_embedding),\n",
    "            ]))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.patch_partition(x)\n",
    "        for regular_block, shifted_block in self.layers:\n",
    "            x = regular_block(x)\n",
    "            x = shifted_block(x)\n",
    "        return x.permute(0, 3, 1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d0ae99f0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-07T01:57:33.687564Z",
     "iopub.status.busy": "2024-07-07T01:57:33.687095Z",
     "iopub.status.idle": "2024-07-07T01:57:33.695494Z",
     "shell.execute_reply": "2024-07-07T01:57:33.694753Z"
    },
    "papermill": {
     "duration": 0.017856,
     "end_time": "2024-07-07T01:57:33.697402",
     "exception": false,
     "start_time": "2024-07-07T01:57:33.679546",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class FeaturePyramidNetwork(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "\n",
    "        # Lateral connections\n",
    "        self.lateral_convs = nn.ModuleList([\n",
    "            nn.Conv2d(in_channels[i], out_channels, kernel_size=1)\n",
    "            for i in range(len(in_channels))\n",
    "        ])\n",
    "\n",
    "        # FPN connections\n",
    "        self.fpn_convs = nn.ModuleList([\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1)\n",
    "            for _ in range(len(in_channels))\n",
    "        ])\n",
    "\n",
    "    def forward(self, features):\n",
    "        laterals = [conv(feature) for feature, conv in zip(features, self.lateral_convs)]\n",
    "        \n",
    "        fpn_features = [laterals[-1]]\n",
    "        for i in range(len(laterals)-2, -1, -1):\n",
    "            up = f.interpolate(fpn_features[0], size=laterals[i].shape[-2:], mode='nearest')\n",
    "            fpn_features.insert(0, laterals[i] + up)\n",
    "        \n",
    "        outputs = [conv(feature) for feature, conv in zip(fpn_features, self.fpn_convs)]\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0fadda8c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-07T01:57:33.732935Z",
     "iopub.status.busy": "2024-07-07T01:57:33.732697Z",
     "iopub.status.idle": "2024-07-07T01:57:33.745757Z",
     "shell.execute_reply": "2024-07-07T01:57:33.744954Z"
    },
    "papermill": {
     "duration": 0.022448,
     "end_time": "2024-07-07T01:57:33.747588",
     "exception": false,
     "start_time": "2024-07-07T01:57:33.725140",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SwinTransformerWithFPN(nn.Module):\n",
    "    def __init__(self, *, hidden_dim, layers, heads, channels=3, num_classes=1, head_dim=32, window_size=4,\n",
    "                 downscaling_factors=(4, 2, 2, 2), relative_pos_embedding=True):\n",
    "        super().__init__()\n",
    "\n",
    "        self.stage1 = StageModule(in_channels=channels, hidden_dimension=hidden_dim, layers=layers[0],\n",
    "                                  downscaling_factor=downscaling_factors[0], num_heads=heads[0], head_dim=head_dim,\n",
    "                                  window_size=window_size, relative_pos_embedding=relative_pos_embedding)\n",
    "        self.stage2 = StageModule(in_channels=hidden_dim, hidden_dimension=hidden_dim * 2, layers=layers[1],\n",
    "                                  downscaling_factor=downscaling_factors[1], num_heads=heads[1], head_dim=head_dim,\n",
    "                                  window_size=window_size, relative_pos_embedding=relative_pos_embedding)\n",
    "        self.stage3 = StageModule(in_channels=hidden_dim * 2, hidden_dimension=hidden_dim * 4, layers=layers[2],\n",
    "                                  downscaling_factor=downscaling_factors[2], num_heads=heads[2], head_dim=head_dim,\n",
    "                                  window_size=window_size, relative_pos_embedding=relative_pos_embedding)\n",
    "        self.stage4 = StageModule(in_channels=hidden_dim * 4, hidden_dimension=hidden_dim * 8, layers=layers[3],\n",
    "                                  downscaling_factor=downscaling_factors[3], num_heads=heads[3], head_dim=head_dim,\n",
    "                                  window_size=window_size, relative_pos_embedding=relative_pos_embedding)\n",
    "\n",
    "        # FPN\n",
    "        self.fpn = FeaturePyramidNetwork(\n",
    "            in_channels=[hidden_dim, hidden_dim * 2, hidden_dim * 4, hidden_dim * 8],\n",
    "            out_channels=256\n",
    "        )\n",
    "\n",
    "        # Global Average Pooling\n",
    "        self.gap = nn.AdaptiveAvgPool2d(1)\n",
    "\n",
    "        # Classification head\n",
    "        self.mlp_head = nn.Sequential(\n",
    "            nn.Linear(256 * 4, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(128, num_classes),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, img):\n",
    "        x1 = self.stage1(img)\n",
    "        x2 = self.stage2(x1)\n",
    "        x3 = self.stage3(x2)\n",
    "        x4 = self.stage4(x3)\n",
    "\n",
    "        # FPN\n",
    "        fpn_features = self.fpn([x1, x2, x3, x4])\n",
    "\n",
    "        # Global Average Pooling on each FPN output\n",
    "        pooled_features = [self.gap(feature) for feature in fpn_features]\n",
    "        \n",
    "        # Concatenate the pooled features\n",
    "        x = torch.cat(pooled_features, dim=1)\n",
    "        x = x.view(x.size(0), -1)\n",
    "\n",
    "        # Classification\n",
    "        return self.mlp_head(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4724c08",
   "metadata": {
    "papermill": {
     "duration": 0.006334,
     "end_time": "2024-07-07T01:57:33.760376",
     "exception": false,
     "start_time": "2024-07-07T01:57:33.754042",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d76973f6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-07T01:57:33.774121Z",
     "iopub.status.busy": "2024-07-07T01:57:33.773886Z",
     "iopub.status.idle": "2024-07-07T01:57:33.778145Z",
     "shell.execute_reply": "2024-07-07T01:57:33.777338Z"
    },
    "papermill": {
     "duration": 0.013128,
     "end_time": "2024-07-07T01:57:33.779916",
     "exception": false,
     "start_time": "2024-07-07T01:57:33.766788",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# class ImageLoader(Dataset):\n",
    "#     def __init__(self, df, file_hdf, transform=None):\n",
    "#         self.df = pd.read_csv(df)\n",
    "#         self.fp_hdf = h5py.File(file_hdf, mode=\"r\")\n",
    "#         self.isic_ids = self.df['isic_id'].values\n",
    "#         self.targets = self.df['target'].values\n",
    "#         self.transform = transform\n",
    "        \n",
    "#     def __len__(self):\n",
    "#         return len(self.isic_ids)\n",
    "\n",
    "#     def __getitem__(self, index):\n",
    "#         isic_id = self.isic_ids[index]\n",
    "#         image = Image.open(BytesIO(self.fp_hdf[isic_id][()]))\n",
    "#         target = self.targets[index]\n",
    "        \n",
    "#         if self.transform:\n",
    "#             return (self.transform(image), target)\n",
    "#         else:\n",
    "#             return (image, target)\n",
    "\n",
    "# # use in dataloader (for balancing the class it give more probability to minority class to get select in batch)\n",
    "# df = pd.read_csv('/kaggle/input/isic-2024-challenge/train-metadata.csv')\n",
    "# labels = df['target'].values\n",
    "# label_counts = Counter(labels) # Calculate the frequency of each class\n",
    "# total_count = len(labels)\n",
    "# class_weights = {label: total_count / count for label, count in label_counts.items()} \n",
    "# sample_weights = [class_weights[label] for label in labels] \n",
    "# sampler = WeightedRandomSampler(weights=sample_weights, num_samples=len(sample_weights), replacement=True)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9def7e62",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-07T01:57:33.793796Z",
     "iopub.status.busy": "2024-07-07T01:57:33.793543Z",
     "iopub.status.idle": "2024-07-07T01:57:33.797441Z",
     "shell.execute_reply": "2024-07-07T01:57:33.796586Z"
    },
    "papermill": {
     "duration": 0.013011,
     "end_time": "2024-07-07T01:57:33.799313",
     "exception": false,
     "start_time": "2024-07-07T01:57:33.786302",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# image_size = 128\n",
    "# train_transforms = transforms.Compose([\n",
    "#     transforms.Resize(image_size),\n",
    "#     transforms.RandomHorizontalFlip(),\n",
    "#     transforms.RandomRotation(degrees=20),\n",
    "#     transforms.ToTensor()\n",
    "# ])\n",
    "\n",
    "\n",
    "# train_dataset = ImageLoader(\n",
    "#     df='/kaggle/input/isic-2024-challenge/train-metadata.csv',\n",
    "#     file_hdf='/kaggle/input/isic-2024-challenge/train-image.hdf5',\n",
    "#     transform=train_transforms\n",
    "# )\n",
    "\n",
    "# train_loader = DataLoader(dataset=train_dataset, \n",
    "#                           batch_size=128, \n",
    "#                           sampler=sampler, \n",
    "#                           shuffle=False, \n",
    "#                           num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c93ac5",
   "metadata": {
    "papermill": {
     "duration": 0.006223,
     "end_time": "2024-07-07T01:57:33.812105",
     "exception": false,
     "start_time": "2024-07-07T01:57:33.805882",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ce6ff2fc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-07T01:57:33.826401Z",
     "iopub.status.busy": "2024-07-07T01:57:33.825968Z",
     "iopub.status.idle": "2024-07-07T01:57:33.830271Z",
     "shell.execute_reply": "2024-07-07T01:57:33.829495Z"
    },
    "papermill": {
     "duration": 0.01349,
     "end_time": "2024-07-07T01:57:33.832121",
     "exception": false,
     "start_time": "2024-07-07T01:57:33.818631",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# class FocalLoss(nn.Module):\n",
    "#     def __init__(self, alpha=0.25, gamma=2):\n",
    "#         super(FocalLoss, self).__init__()\n",
    "#         self.alpha = alpha\n",
    "#         self.gamma = gamma\n",
    "\n",
    "#     def forward(self, inputs, targets):\n",
    "#         BCE_loss = nn.functional.binary_cross_entropy(inputs, targets, reduction='none')\n",
    "#         pt = torch.exp(-BCE_loss)\n",
    "#         F_loss = self.alpha * (1-pt)**self.gamma * BCE_loss\n",
    "#         return torch.mean(F_loss)\n",
    "\n",
    "# def performance_metrics(predictions, labels, threshold=0.5):\n",
    "#     binary_predictions = (predictions >= threshold).float()\n",
    "    \n",
    "#     true_positives = torch.sum((binary_predictions == 1) & (labels == 1)).item()\n",
    "#     true_negatives = torch.sum((binary_predictions == 0) & (labels == 0)).item()\n",
    "#     false_positives = torch.sum((binary_predictions == 1) & (labels == 0)).item()\n",
    "#     false_negatives = torch.sum((binary_predictions == 0) & (labels == 1)).item()\n",
    "    \n",
    "#     accuracy = (true_positives + true_negatives) / (true_positives + true_negatives + false_positives + false_negatives)\n",
    "    \n",
    "#     precision = true_positives / (true_positives + false_positives) if (true_positives + false_positives) > 0 else 0.0\n",
    "#     recall = true_positives / (true_positives + false_negatives) if (true_positives + false_negatives) > 0 else 0.0\n",
    "    \n",
    "#     return accuracy, precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1bb006da",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-07T01:57:33.846816Z",
     "iopub.status.busy": "2024-07-07T01:57:33.846318Z",
     "iopub.status.idle": "2024-07-07T01:57:33.852371Z",
     "shell.execute_reply": "2024-07-07T01:57:33.851515Z"
    },
    "papermill": {
     "duration": 0.015555,
     "end_time": "2024-07-07T01:57:33.854184",
     "exception": false,
     "start_time": "2024-07-07T01:57:33.838629",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# device = 'cuda'\n",
    "# model = SwinTransformerWithFPN(\n",
    "#     hidden_dim=96,\n",
    "#     layers=(2, 2, 6, 2),\n",
    "#     heads=(3, 6, 12, 24),\n",
    "#     num_classes=1\n",
    "# ).to(device)\n",
    "\n",
    "# # Training parameters\n",
    "# epochs = 30\n",
    "# loss_fn = FocalLoss(alpha=0.25, gamma=2)\n",
    "\n",
    "# # Optimizer with weight decay (L2 regularization)\n",
    "# optimizer = torch.optim.AdamW(model.parameters(), lr=0.001, weight_decay=0.01)\n",
    "\n",
    "# # Learning rate scheduler\n",
    "# scheduler = CosineAnnealingLR(optimizer, T_max=epochs)\n",
    "\n",
    "# # Training loop\n",
    "# train_loss = []\n",
    "# train_accuracy = []\n",
    "# train_precision = []\n",
    "# train_recall = []\n",
    "# learning_rates = []\n",
    "\n",
    "# for epoch in range(epochs):\n",
    "#     print(f'Epoch {epoch + 1} / {epochs}')\n",
    "#     model.train()\n",
    "#     epoch_loss = 0\n",
    "#     epoch_accuracy = 0\n",
    "#     epoch_precision = 0\n",
    "#     epoch_recall = 0\n",
    "#     count = 0\n",
    "\n",
    "#     for images, labels in tqdm(train_loader):\n",
    "#         optimizer.zero_grad()\n",
    "#         images = images.to(device)\n",
    "#         labels = labels.unsqueeze(1).float().to(device)\n",
    "        \n",
    "#         outputs = model(images)\n",
    "#         loss = loss_fn(outputs, labels)\n",
    "        \n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "        \n",
    "#         epoch_loss += loss.item()\n",
    "#         temp = performance_metrics(outputs, labels)\n",
    "#         epoch_accuracy += temp[0]\n",
    "#         epoch_precision += temp[1]\n",
    "#         epoch_recall += temp[2]\n",
    "#         count += 1\n",
    "    \n",
    "#     # Calculate average metrics for the epoch\n",
    "#     avg_loss = epoch_loss / count\n",
    "#     avg_accuracy = epoch_accuracy / count\n",
    "#     avg_precision = epoch_precision / count\n",
    "#     avg_recall = epoch_recall / count\n",
    "    \n",
    "#     train_loss.append(avg_loss)\n",
    "#     train_accuracy.append(avg_accuracy)\n",
    "#     train_precision.append(avg_precision)\n",
    "#     train_recall.append(avg_recall)\n",
    "#     learning_rates.append(optimizer.param_groups[0]['lr'])\n",
    "    \n",
    "#     print(f'Loss: {avg_loss:.4f}, Accuracy: {avg_accuracy:.4f}, Precision: {avg_precision:.4f}, Recall: {avg_recall:.4f}')\n",
    "#     print(f'Learning Rate: {optimizer.param_groups[0][\"lr\"]:.6f}')\n",
    "    \n",
    "#     if (epoch + 1) % 5 == 0:\n",
    "#         torch.save(model.state_dict(), f'/kaggle/working/my_model_epoch_{epoch+1}.pt')\n",
    "    \n",
    "#     # Step the scheduler\n",
    "#     scheduler.step()\n",
    "\n",
    "# # Save training history\n",
    "# history = {\n",
    "#     'train_loss': train_loss,\n",
    "#     'train_accuracy': train_accuracy,\n",
    "#     'train_precision': train_precision,\n",
    "#     'train_recall': train_recall,\n",
    "#     'learning_rates': learning_rates\n",
    "# }\n",
    "\n",
    "# with open('/kaggle/working/train_metrics.json', 'w') as f:\n",
    "#     json.dump({k: [float(v) for v in vals] for k, vals in history.items()}, f)\n",
    "\n",
    "# print(\"Training completed and metrics saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab49caa4",
   "metadata": {
    "papermill": {
     "duration": 0.006251,
     "end_time": "2024-07-07T01:57:33.879995",
     "exception": false,
     "start_time": "2024-07-07T01:57:33.873744",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Prediciton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "26ef764d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-07T01:57:33.894111Z",
     "iopub.status.busy": "2024-07-07T01:57:33.893827Z",
     "iopub.status.idle": "2024-07-07T01:57:37.300195Z",
     "shell.execute_reply": "2024-07-07T01:57:37.298828Z"
    },
    "papermill": {
     "duration": 3.416417,
     "end_time": "2024-07-07T01:57:37.302926",
     "exception": false,
     "start_time": "2024-07-07T01:57:33.886509",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions completed and saved to submission.csv\n"
     ]
    }
   ],
   "source": [
    "# device='cuda'\n",
    "# class TestImageLoader(Dataset):\n",
    "#     def __init__(self, file_hdf, transform=None):\n",
    "#         self.fp_hdf = h5py.File(file_hdf, mode=\"r\")\n",
    "#         self.isic_ids = list(self.fp_hdf.keys())\n",
    "#         self.transform = transform\n",
    "        \n",
    "#     def __len__(self):\n",
    "#         return len(self.isic_ids)\n",
    "    \n",
    "#     def __getitem__(self, index):\n",
    "#         isic_id = self.isic_ids[index]\n",
    "#         image = Image.open(BytesIO(self.fp_hdf[isic_id][()]))\n",
    "        \n",
    "#         if self.transform:\n",
    "#             return self.transform(image), isic_id\n",
    "#         else:\n",
    "#             return image, isic_id\n",
    "\n",
    "# test_transform = transforms.Compose([\n",
    "#     transforms.Resize((128, 128)),  \n",
    "#     transforms.ToTensor()  \n",
    "# ])\n",
    "\n",
    "# test_dataset = TestImageLoader('/kaggle/input/isic-2024-challenge/test-image.hdf5', transform=test_transform)\n",
    "\n",
    "# test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False, num_workers=4)\n",
    "\n",
    "\n",
    "# model = SwinTransformerWithFPN(\n",
    "#     hidden_dim=96,\n",
    "#     layers=(2, 2, 6, 2),\n",
    "#     heads=(3, 6, 12, 24),\n",
    "#     num_classes=1\n",
    "# ).to(device)\n",
    "\n",
    "# model.load_state_dict(torch.load('/kaggle/input/model2/my_model_epoch_20.pt'))\n",
    "# model.eval()\n",
    "\n",
    "# results = {}\n",
    "# with torch.no_grad():\n",
    "#     for images, isic_ids in test_loader:\n",
    "#         images = images.to(device)\n",
    "#         outputs = model(images)\n",
    "        \n",
    "#         for isic_id, prob in zip(isic_ids, outputs):\n",
    "#             results[isic_id] = prob.item()\n",
    "\n",
    "# df = pd.DataFrame(list(results.items()), columns=['isic_id', 'target'])\n",
    "# df.to_csv('/kaggle/working/submission.csv' , index=False)\n",
    "# print(\"Predictions completed and saved to submission.csv\")\n",
    "# test_dataset.fp_hdf.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f3541aa",
   "metadata": {
    "papermill": {
     "duration": 0.007441,
     "end_time": "2024-07-07T01:57:37.318410",
     "exception": false,
     "start_time": "2024-07-07T01:57:37.310969",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "--------------------------------------------------------"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 8940774,
     "sourceId": 63056,
     "sourceType": "competition"
    },
    {
     "datasetId": 5313873,
     "sourceId": 8831388,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5314231,
     "sourceId": 8831855,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5346863,
     "sourceId": 8888786,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30733,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 50.355555,
   "end_time": "2024-07-07T01:57:39.900194",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-07-07T01:56:49.544639",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
