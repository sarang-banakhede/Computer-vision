{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class conv_block(nn.Module):\n",
    "    def __init__(self, in_c, out_c, act=True):\n",
    "        super().__init__()\n",
    "\n",
    "        layers = [nn.Conv2d(in_c, out_c, kernel_size=3, padding=1)]\n",
    "\n",
    "        if act == True:\n",
    "            layers.append(nn.BatchNorm2d(out_c))\n",
    "            layers.append(nn.ReLU(inplace=True))\n",
    "\n",
    "        self.conv = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "\n",
    "class encoder_block(nn.Module):\n",
    "    def __init__(self, in_c, out_c):\n",
    "        super().__init__()\n",
    "\n",
    "        self.c1 = nn.Sequential(\n",
    "            conv_block(in_c, out_c),\n",
    "            conv_block(out_c, out_c)\n",
    "        )\n",
    "        self.p1 = nn.MaxPool2d((2, 2))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.c1(x)\n",
    "        p = self.p1(x)\n",
    "        return x, p\n",
    "\n",
    "class unet3plus(nn.Module):\n",
    "    def __init__(self, num_classes=1):\n",
    "        super().__init__()\n",
    "\n",
    "        \"\"\" Encoder \"\"\"\n",
    "        self.e1 = encoder_block(3, 64)\n",
    "        self.e2 = encoder_block(64, 128)\n",
    "        self.e3 = encoder_block(128, 256)\n",
    "        self.e4 = encoder_block(256, 512)\n",
    "\n",
    "        \"\"\" Bottleneck \"\"\"\n",
    "        self.e5 = nn.Sequential(\n",
    "            conv_block(512, 1024),\n",
    "            conv_block(1024, 1024)\n",
    "        )\n",
    "\n",
    "        \"\"\" Decoder 4 \"\"\"\n",
    "        self.e1_d4 = conv_block(64, 64)\n",
    "        self.e2_d4 = conv_block(128, 64)\n",
    "        self.e3_d4 = conv_block(256, 64)\n",
    "        self.e4_d4 = conv_block(512, 64)\n",
    "        self.e5_d4 = conv_block(1024, 64)\n",
    "\n",
    "        self.d4 = conv_block(64*5, 64)\n",
    "\n",
    "        \"\"\" Decoder 3 \"\"\"\n",
    "        self.e1_d3 = conv_block(64, 64)\n",
    "        self.e2_d3 = conv_block(128, 64)\n",
    "        self.e3_d3 = conv_block(256, 64)\n",
    "        self.e4_d3 = conv_block(64, 64)\n",
    "        self.e5_d3 = conv_block(1024, 64)\n",
    "\n",
    "        self.d3 = conv_block(64*5, 64)\n",
    "\n",
    "        \"\"\" Decoder 2 \"\"\"\n",
    "        self.e1_d2 = conv_block(64, 64)\n",
    "        self.e2_d2 = conv_block(128, 64)\n",
    "        self.e3_d2 = conv_block(64, 64)\n",
    "        self.e4_d2 = conv_block(64, 64)\n",
    "        self.e5_d2 = conv_block(1024, 64)\n",
    "\n",
    "        self.d2 = conv_block(64*5, 64)\n",
    "\n",
    "        \"\"\" Decoder 1 \"\"\"\n",
    "        self.e1_d1 = conv_block(64, 64)\n",
    "        self.e2_d1 = conv_block(64, 64)\n",
    "        self.e3_d1 = conv_block(64, 64)\n",
    "        self.e4_d1 = conv_block(64, 64)\n",
    "        self.e5_d1 = conv_block(1024, 64)\n",
    "\n",
    "        self.d1 = conv_block(64*5, 64)\n",
    "\n",
    "        \"\"\" Output \"\"\"\n",
    "        self.y1 = nn.Conv2d(64, num_classes, kernel_size=3, padding=1)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        \"\"\" Encoder \"\"\"\n",
    "        e1, p1 = self.e1(inputs)\n",
    "        e2, p2 = self.e2(p1)\n",
    "        e3, p3 = self.e3(p2)\n",
    "        e4, p4 = self.e4(p3)\n",
    "\n",
    "        \"\"\" Bottleneck \"\"\"\n",
    "        e5 = self.e5(p4)\n",
    "\n",
    "        \"\"\" Decoder 4 \"\"\"\n",
    "        e1_d4 = F.max_pool2d(e1, kernel_size=8, stride=8)\n",
    "        e1_d4 = self.e1_d4(e1_d4)\n",
    "\n",
    "        e2_d4 = F.max_pool2d(e2, kernel_size=4, stride=4)\n",
    "        e2_d4 = self.e2_d4(e2_d4)\n",
    "\n",
    "        e3_d4 = F.max_pool2d(e3, kernel_size=2, stride=2)\n",
    "        e3_d4 = self.e3_d4(e3_d4)\n",
    "\n",
    "        e4_d4 = self.e4_d4(e4)\n",
    "\n",
    "        e5_d4 = F.interpolate(e5, scale_factor=2, mode=\"bilinear\", align_corners=True)\n",
    "        e5_d4 = self.e5_d4(e5_d4)\n",
    "\n",
    "        d4 = torch.cat([e1_d4, e2_d4, e3_d4, e4_d4, e5_d4], dim=1)\n",
    "        d4 = self.d4(d4)\n",
    "\n",
    "        \"\"\" Decoder 3 \"\"\"\n",
    "        e1_d3 = F.max_pool2d(e1, kernel_size=4, stride=4)\n",
    "        e1_d3 = self.e1_d3(e1_d3)\n",
    "\n",
    "        e2_d3 = F.max_pool2d(e2, kernel_size=2, stride=2)\n",
    "        e2_d3 = self.e2_d3(e2_d3)\n",
    "\n",
    "        e3_d3 = self.e3_d3(e3)\n",
    "\n",
    "        e4_d3 = F.interpolate(d4, scale_factor=2, mode=\"bilinear\", align_corners=True)\n",
    "        e4_d3 = self.e4_d3(e4_d3)\n",
    "\n",
    "        e5_d3 = F.interpolate(e5, scale_factor=4, mode=\"bilinear\", align_corners=True)\n",
    "        e5_d3 = self.e5_d3(e5_d3)\n",
    "\n",
    "        d3 = torch.cat([e1_d3, e2_d3, e3_d3, e4_d3, e5_d3], dim=1)\n",
    "        d3 = self.d3(d3)\n",
    "\n",
    "        \"\"\" Decoder 2 \"\"\"\n",
    "        e1_d2 = F.max_pool2d(e1, kernel_size=2, stride=2)\n",
    "        e1_d2 = self.e1_d2(e1_d2)\n",
    "\n",
    "        e2_d2 = self.e2_d2(e2)\n",
    "\n",
    "        e3_d2 = F.interpolate(d3, scale_factor=2, mode=\"bilinear\", align_corners=True)\n",
    "        e3_d2 = self.e3_d2(e3_d2)\n",
    "\n",
    "        e4_d2 = F.interpolate(d4, scale_factor=4, mode=\"bilinear\", align_corners=True)\n",
    "        e4_d2 = self.e4_d2(e4_d2)\n",
    "\n",
    "        e5_d2 = F.interpolate(e5, scale_factor=8, mode=\"bilinear\", align_corners=True)\n",
    "        e5_d2 = self.e5_d2(e5_d2)\n",
    "\n",
    "        d2 = torch.cat([e1_d2, e2_d2, e3_d2, e4_d2, e5_d2], dim=1)\n",
    "        d2 = self.d2(d2)\n",
    "\n",
    "        \"\"\" Decoder 1 \"\"\"\n",
    "        e1_d1 = self.e1_d1(e1)\n",
    "\n",
    "        e2_d1 = F.interpolate(d2, scale_factor=2, mode=\"bilinear\", align_corners=True)\n",
    "        e2_d1 = self.e2_d1(e2_d1)\n",
    "\n",
    "        e3_d1 = F.interpolate(d3, scale_factor=4, mode=\"bilinear\", align_corners=True)\n",
    "        e3_d1 = self.e3_d1(e3_d1)\n",
    "\n",
    "        e4_d1 = F.interpolate(d4, scale_factor=8, mode=\"bilinear\", align_corners=True)\n",
    "        e4_d1 = self.e4_d1(e4_d1)\n",
    "\n",
    "        e5_d1 = F.interpolate(e5, scale_factor=16, mode=\"bilinear\", align_corners=True)\n",
    "        e5_d1 = self.e5_d1(e5_d1)\n",
    "\n",
    "        d1 = torch.cat([e1_d1, e2_d1, e3_d1, e4_d1, e5_d1], dim=1)\n",
    "        d1 = self.d1(d1)\n",
    "\n",
    "        \"\"\" Output \"\"\"\n",
    "        y1 = self.y1(d1)\n",
    "\n",
    "        return y1"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
